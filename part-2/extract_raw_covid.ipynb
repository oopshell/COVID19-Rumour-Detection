{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import time\n",
    "import re\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Data(data_file, data_json, label_file):\n",
    "    # open train.txt\n",
    "    with open(data_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    jsonFiles = glob(data_json + '/*.json')\n",
    "    \n",
    "    # extract tweet ids from train_data.json names\n",
    "    regex = re.compile('[0-9]{12,22}')\n",
    "    json_lst = []\n",
    "    for j in jsonFiles:   \n",
    "        b=regex.findall(j)\n",
    "        json_lst.append(b)\n",
    "    \n",
    "    data_list = {}\n",
    "    num = 0\n",
    "    \n",
    "    # extract labels\n",
    "    labels = []\n",
    "    if label_file:\n",
    "        with open(label_file) as f:\n",
    "            label_lines = f.readlines()\n",
    "        for label in label_lines:\n",
    "            if label.strip('\\n') == 'rumour':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        tweets = lines[i].strip('\\n').split(',')\n",
    "        target_tweet = {}\n",
    "        retweets = []\n",
    "\n",
    "        if [tweets[0]] in json_lst:\n",
    "    \n",
    "            for j in range(len(tweets)):\n",
    "                filePath = data_json+tweets[j]+'.json'\n",
    "                if j == 0 :\n",
    "                    json_data_file = open(filePath,'r').read()\n",
    "                    json_data = json.loads(json_data_file)\n",
    "                    \n",
    "                    target_tweet['source tweet id']=json_data['id_str']\n",
    "                    target_tweet['source tweet text']=json_data['text']\n",
    "       \n",
    "                if j!=0 and [tweets[j]] in json_lst:\n",
    "                    json_data_file = open(filePath,'r').read()\n",
    "                    json_data = json.loads(json_data_file)\n",
    "\n",
    "                    # list the retweets in a chronongical order\n",
    "                    retweets.append((time.strptime(json_data['created_at'],'%a %b %d %H:%M:%S %z %Y'), json_data['text']))\n",
    "                    sort_time_retweets = sorted(retweets, key=lambda x: x[0])\n",
    "                    sort_retweets = [t[1] for t in sort_time_retweets]\n",
    "                    target_tweet['retweets']=sort_retweets\n",
    "\n",
    "            data_list[num] = target_tweet\n",
    "            num += 1\n",
    "        elif label_file:\n",
    "            labels[i] = 2\n",
    "            \n",
    "    labels = list(filter((2).__ne__, labels))\n",
    "        \n",
    "    return data_list, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15972\n"
     ]
    }
   ],
   "source": [
    "covid_data_file = 'covid.data.txt'\n",
    "covid_data_json = 'covid-data/'\n",
    "\n",
    "covid_data_d, covid_labels=read_Data(covid_data_file, covid_data_json,\"\")\n",
    "print(len(covid_data_d))\n",
    "\n",
    "with open('total_covid_data.json', 'w') as f:\n",
    "    json.dump(covid_data_d, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcc88a5c2b6accdcaf39c87a931cb715cc1ab684beb32819a99a5a377f971b8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
