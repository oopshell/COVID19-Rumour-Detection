{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english')) # note: stopwords are all in lowercase\n",
    "\n",
    "def tokenizing_english_xstopwords(tw_text):\n",
    "    \n",
    "#     text = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"URL\", text)  # Replace urls with special token\n",
    "#     text = text.replace(\"\\'s\", \"\")\n",
    "#     text = text.replace(\"\\'\", \"\")\n",
    "#     text = text.replace(\"n\\'t\", \" n\\'t\")\n",
    "#     text = text.replace(\"@\", \"\")\n",
    "#     text = text.replace(\"#\", \"\")\n",
    "#     text = text.replace(\"_\", \" \")\n",
    "#     text = text.replace(\"-\", \" \")\n",
    "#     text = text.replace(\"&amp;\", \"\")\n",
    "#     text = text.replace(\"&gt;\", \"\")\n",
    "#     text = text.replace(\"\\\"\", \"\")\n",
    "#     text = text.replace(\".\", \"\")\n",
    "#     text = text.replace(\",\", \"\")\n",
    "#     text = text.replace(\"(\", \"\")\n",
    "#     text = text.replace(\")\", \"\")\n",
    "#     text = ' '.join(text.split())\n",
    "    \n",
    "    \n",
    "    tw_token = tt.tokenize(tw_text)\n",
    "    tw_token_lower = [w.lower() for w in tw_token]\n",
    "    tw_token_lower_english = [w for w in tw_token_lower if w.isalpha()]\n",
    "    tw_token_lower_english_xstopword = [w for w in tw_token_lower_english if not w in stopwords]\n",
    "    return tw_token_lower_english_xstopword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52d9637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regularly rinsing nose saline help prevent inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>french police chief killed attack devastating ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus disease covid advice public wear m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ottawa police confirm multiple suspects shooti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>primary focus government alleviate suffering d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>desperate ted cruz claims planned parenthood s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>thoughts prayers enough pres obama speaks mass...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>police surrounded building suspected attackers...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>joseph smith translated gift power god come fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>help socialism need bad slacklining excellent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1895 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tw_text_re label0 label1\n",
       "0     regularly rinsing nose saline help prevent inf...      1      0\n",
       "1     french police chief killed attack devastating ...      0      1\n",
       "2     coronavirus disease covid advice public wear m...      1      0\n",
       "3     ottawa police confirm multiple suspects shooti...      1      0\n",
       "4     primary focus government alleviate suffering d...      1      0\n",
       "...                                                 ...    ...    ...\n",
       "1890  desperate ted cruz claims planned parenthood s...      0      1\n",
       "1891  thoughts prayers enough pres obama speaks mass...      0      1\n",
       "1892  police surrounded building suspected attackers...      1      0\n",
       "1893  joseph smith translated gift power god come fo...      1      0\n",
       "1894  help socialism need bad slacklining excellent ...      1      0\n",
       "\n",
       "[1895 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('train.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "labels = []\n",
    "with open('train.label.txt') as f:\n",
    "    labels = f.readlines()\n",
    "data_label = [lb.splitlines()[0] for lb in labels]\n",
    "data_label_01 = []\n",
    "for lb in data_label:\n",
    "    if lb == 'rumour':\n",
    "        data_label_01.append((0, 1))\n",
    "    else:\n",
    "        data_label_01.append((1, 0))\n",
    "\n",
    "\n",
    "tw_path = 'data/train-data/'\n",
    "col = ['tw_text_re', 'label0', 'label1']\n",
    "inx = range(len(data_label))\n",
    "data_train = pd.DataFrame(columns=col, index=inx)\n",
    "# data_train = pd.DataFrame(columns=col)\n",
    "# data_train['label'] = data_label\n",
    "# display(data_train)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "    \n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path+twid+'.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "    \n",
    "    # data_train['tw_text_re'][i] = tw_text_re\n",
    "    data_train['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "    data_train['label0'][i] = data_label_01[i][0]\n",
    "    data_train['label1'][i] = data_label_01[i][1]\n",
    "    \n",
    "\n",
    "data_train_drop = data_train.dropna().reset_index(drop=True)\n",
    "display(data_train_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "57dbd05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new low obama spent money close natl parks shu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news shots fired parliament hill follow develo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worry ppl threat homeland man wearing body arm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wash fruit vegetables time handling wash hands...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lit like rainbow awesome getting better light ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>obama pattern mass shootings country parallel ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>photo white house lit rainbow colors high gay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>covid virus transmitted areas hot humid climat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>number ppl killed mass shootings obama tenure ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>long incubation period covid incubation period...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tw_text_re label0 label1\n",
       "0     new low obama spent money close natl parks shu...      0      1\n",
       "1     news shots fired parliament hill follow develo...      1      0\n",
       "2     worry ppl threat homeland man wearing body arm...      0      1\n",
       "3     wash fruit vegetables time handling wash hands...      1      0\n",
       "4     lit like rainbow awesome getting better light ...      1      0\n",
       "...                                                 ...    ...    ...\n",
       "2945  obama pattern mass shootings country parallel ...      0      1\n",
       "2946  photo white house lit rainbow colors high gay ...      1      0\n",
       "2947  covid virus transmitted areas hot humid climat...      1      0\n",
       "2948  number ppl killed mass shootings obama tenure ...      0      1\n",
       "2949  long incubation period covid incubation period...      1      0\n",
       "\n",
       "[2950 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "label_arr = data_train_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "d = label_count_0 - label_count_1\n",
    "\n",
    "data_train_drop_1 = data_train_drop[data_train_drop['label1'] == 1]\n",
    "data_sample = data_train_drop_1.sample(n=d, replace=True, random_state=90042)\n",
    "data_train_drop = pd.concat([data_train_drop, data_sample], ignore_index = True).reset_index()\n",
    "\n",
    "data_train_drop = data_train_drop.drop(['index'], axis=1)\n",
    "data_train_drop = data_train_drop.to_numpy()\n",
    "np.random.shuffle(data_train_drop)\n",
    "data_train_drop = pd.DataFrame(data_train_drop, columns=['tw_text_re', 'label0', 'label1'])\n",
    "data_train_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0a5184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475\n",
      "1475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_arr = data_train_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "print(label_count_1)\n",
    "print(label_count_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d601598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid fact hand dryers effective killing new c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expect result pending antibody test please may...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid spread people catch covid others virus d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>every news outlet using headlines like antibio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>researcher encounter goliath birdeater largest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>cure covid however several ongoing clinical tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>speculation arrested banksy debuts new mural b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>questions answered reply number get correct an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>operation ku klux klan never stopped watching ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>exposing sun temperatures higher degrees preve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>632 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re label0 label1\n",
       "0    covid fact hand dryers effective killing new c...      1      0\n",
       "1    expect result pending antibody test please may...      1      0\n",
       "2    covid spread people catch covid others virus d...      1      0\n",
       "3    every news outlet using headlines like antibio...      1      0\n",
       "4    researcher encounter goliath birdeater largest...      1      0\n",
       "..                                                 ...    ...    ...\n",
       "627  cure covid however several ongoing clinical tr...      1      0\n",
       "628  speculation arrested banksy debuts new mural b...      0      1\n",
       "629  questions answered reply number get correct an...      1      0\n",
       "630  operation ku klux klan never stopped watching ...      0      1\n",
       "631  exposing sun temperatures higher degrees preve...      1      0\n",
       "\n",
       "[632 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# lines = []\n",
    "with open('dev.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "# labels = []\n",
    "with open('dev.label.txt') as f:\n",
    "    labels = f.readlines()\n",
    "data_label = [lb.splitlines()[0] for lb in labels]\n",
    "data_label_01 = []\n",
    "for lb in data_label:\n",
    "    if lb == 'rumour':\n",
    "        data_label_01.append((0, 1))\n",
    "    else:\n",
    "        data_label_01.append((1, 0))\n",
    "\n",
    "tw_path = 'data/dev-data/'\n",
    "col = ['tw_text_re', 'label0', 'label1']\n",
    "inx = range(len(data_label))\n",
    "data_dev = pd.DataFrame(columns=col, index=inx)\n",
    "# data_dev = pd.DataFrame(columns=col)\n",
    "# data_dev['label'] = data_label\n",
    "# display(data_dev)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "\n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path + twid + '.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "\n",
    "    # data_dev['tw_text_re'][i] = tw_text_re\n",
    "    data_dev['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "    data_dev['label0'][i] = data_label_01[i][0]\n",
    "    data_dev['label1'][i] = data_label_01[i][1]\n",
    "\n",
    "data_dev_drop = data_dev.dropna().reset_index(drop=True)\n",
    "display(data_dev_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4923b86b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live citizens assembly talk citizens assembly ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world health organization insists new coronavi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poll lead shrinks edge gop vanishes believe po...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptoms covid covid airborne answers biggest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>covid virus transmitted areas hot humid climat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>flu much bigger threat coronavirus written th ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>macklemore announced today joined isis lol mac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>exquisite good chop translucent butterfly beau...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>texas health officials say person test positiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re label0 label1\n",
       "0    live citizens assembly talk citizens assembly ...      1      0\n",
       "1    world health organization insists new coronavi...      1      0\n",
       "2    poll lead shrinks edge gop vanishes believe po...      0      1\n",
       "3    symptoms covid covid airborne answers biggest ...      1      0\n",
       "4                                                           1      0\n",
       "..                                                 ...    ...    ...\n",
       "981  covid virus transmitted areas hot humid climat...      1      0\n",
       "982  flu much bigger threat coronavirus written th ...      0      1\n",
       "983  macklemore announced today joined isis lol mac...      0      1\n",
       "984  exquisite good chop translucent butterfly beau...      0      1\n",
       "985  texas health officials say person test positiv...      1      0\n",
       "\n",
       "[986 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "label_arr = data_dev_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "d = label_count_0 - label_count_1\n",
    "\n",
    "data_dev_drop_1 = data_dev_drop[data_dev_drop['label1'] == 1]\n",
    "data_sample = data_dev_drop_1.sample(n=d, replace=True, random_state=90042)\n",
    "data_dev_drop = pd.concat([data_dev_drop, data_sample], ignore_index = True).reset_index()\n",
    "\n",
    "data_dev_drop = data_dev_drop.drop(['index'], axis=1)\n",
    "data_dev_drop = data_dev_drop.to_numpy()\n",
    "np.random.shuffle(data_dev_drop)\n",
    "data_dev_drop = pd.DataFrame(data_dev_drop, columns=['tw_text_re', 'label0', 'label1'])\n",
    "data_dev_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c02d19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_arr = data_dev_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "print(label_count_1)\n",
    "print(label_count_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid spread thanks wcco station trust media p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate keep saying capitalism implode without vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q covid influenza viruses different q covid in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una de les q coronaviruses de la pÃ gina web de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely blame politicians whoever else invo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>man dies disease situaÃ§Ã£o meio que irÃ´nica man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>holy shit doritos flavored mountain dew lost a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>banksy account joins cartoonists support je su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>q members international heal q members adviser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>covid caught person symptoms main way disease ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re\n",
       "0    covid spread thanks wcco station trust media p...\n",
       "1    hate keep saying capitalism implode without vi...\n",
       "2    q covid influenza viruses different q covid in...\n",
       "3    una de les q coronaviruses de la pÃ gina web de...\n",
       "4    absolutely blame politicians whoever else invo...\n",
       "..                                                 ...\n",
       "553  man dies disease situaÃ§Ã£o meio que irÃ´nica man...\n",
       "554  holy shit doritos flavored mountain dew lost a...\n",
       "555  banksy account joins cartoonists support je su...\n",
       "556  q members international heal q members adviser...\n",
       "557  covid caught person symptoms main way disease ...\n",
       "\n",
       "[558 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# lines = []\n",
    "with open('test.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "\n",
    "tw_path = 'data/tweet-objects/'\n",
    "col = ['tw_text_re']\n",
    "inx = range(len(data_label))\n",
    "data_test = pd.DataFrame(columns=col, index=inx)\n",
    "# display(data_test)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "\n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path + twid + '.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "\n",
    "    # data_test['tw_text_re'][i] = tw_text_re\n",
    "    data_test['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "\n",
    "data_test_drop = data_test.dropna().reset_index(drop=True)\n",
    "display(data_test_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b63374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train, y_train = data_train_drop.loc[:, 'tw_text_re'], data_train_drop.loc[:, 'label0':'label1']\n",
    "x_dev, y_dev = data_dev_drop.loc[:, 'tw_text_re'], data_dev_drop.loc[:, 'label0':'label1']\n",
    "x_test = data_test_drop.loc[:, 'tw_text_re']\n",
    "\n",
    "x_train = np.array(x_train)#.astype(np.float32)\n",
    "x_dev = np.array(x_dev)#.astype(np.float32)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "y_dev = np.array(y_dev).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d9aa6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01e11040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d21db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f042099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f1b0b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 17221\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode=\"count\") #BOW representation\n",
    "x_dev = tokenizer.texts_to_matrix(x_dev, mode=\"count\") #BOW representation\n",
    "x_test = tokenizer.texts_to_matrix(x_test, mode=\"count\") #BOW representation\n",
    "\n",
    "vocab_size = x_train.shape[1]\n",
    "print(\"Vocab size =\", vocab_size)\n",
    "# print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38026e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feedforward-bow-input\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 1000)              17222000  \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 18,225,002\n",
      "Trainable params: 18,225,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 13s 134ms/step - loss: 0.4598 - accuracy: 0.8213 - val_loss: 0.5466 - val_accuracy: 0.8073\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 11s 118ms/step - loss: 0.0414 - accuracy: 0.9843 - val_loss: 0.4518 - val_accuracy: 0.8641\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 12s 132ms/step - loss: 0.0329 - accuracy: 0.9845 - val_loss: 0.5236 - val_accuracy: 0.8671\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 13s 138ms/step - loss: 0.0307 - accuracy: 0.9839 - val_loss: 0.6385 - val_accuracy: 0.8387\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 45s 489ms/step - loss: 0.0329 - accuracy: 0.9835 - val_loss: 0.6651 - val_accuracy: 0.8367\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 15s 163ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.6111 - val_accuracy: 0.8479\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 15s 163ms/step - loss: 0.0307 - accuracy: 0.9835 - val_loss: 0.7407 - val_accuracy: 0.8316\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 13s 137ms/step - loss: 0.0283 - accuracy: 0.9858 - val_loss: 0.7353 - val_accuracy: 0.8367\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 11s 116ms/step - loss: 0.0281 - accuracy: 0.9861 - val_loss: 0.7645 - val_accuracy: 0.8347\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 10s 107ms/step - loss: 0.0286 - accuracy: 0.9873 - val_loss: 0.6261 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 11s 120ms/step - loss: 0.0268 - accuracy: 0.9859 - val_loss: 0.7045 - val_accuracy: 0.8377\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 10s 109ms/step - loss: 0.0291 - accuracy: 0.9856 - val_loss: 0.6482 - val_accuracy: 0.8489\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 10s 108ms/step - loss: 0.0293 - accuracy: 0.9828 - val_loss: 0.7265 - val_accuracy: 0.8367\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 11s 119ms/step - loss: 0.0285 - accuracy: 0.9868 - val_loss: 0.7205 - val_accuracy: 0.8458\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 11s 115ms/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 0.7490 - val_accuracy: 0.8408\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 14s 147ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 0.6786 - val_accuracy: 0.8479\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 18s 192ms/step - loss: 0.0272 - accuracy: 0.9864 - val_loss: 0.7804 - val_accuracy: 0.8367\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 19s 205ms/step - loss: 0.0285 - accuracy: 0.9867 - val_loss: 0.7264 - val_accuracy: 0.8489\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.0293 - accuracy: 0.9842 - val_loss: 0.8464 - val_accuracy: 0.8245\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.0256 - accuracy: 0.9886 - val_loss: 0.7234 - val_accuracy: 0.8428\n",
      "\n",
      "Testing Accuracy:  0.8428\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "#model definition\n",
    "model = Sequential(name=\"feedforward-bow-input\")\n",
    "# model.add(layers.Dense(10, input_dim=vocab_size, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.add(layers.Dense(1000, input_dim=vocab_size, activation='elu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1000, activation='elu'))\n",
    "# model.add(layers.Dense(10, activation='elu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "#since it's a binary classification problem, we use a binary cross entropy loss here binary_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#training\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, verbose=True, validation_data=(x_dev, y_dev), batch_size=32)\n",
    "# model.fit(x_train, y_train, epochs=20, verbose=True, batch_size=16)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_dev, y_dev, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6273c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b1836154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9717879e-01, 2.8211770e-03],\n",
       "       [1.0000000e+00, 2.9298658e-08],\n",
       "       [9.9981779e-01, 1.8219123e-04],\n",
       "       ...,\n",
       "       [5.3621910e-04, 9.9946374e-01],\n",
       "       [9.9999666e-01, 3.3396727e-06],\n",
       "       [9.9999988e-01, 1.1146662e-07]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "yhat = model.predict(x_test)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e206c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "797e9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = yhat.copy()\n",
    "# result[result>=0.5] = 1\n",
    "# result[result<0.5] = 0\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d7d2865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Predicted\n",
       "0      0         0\n",
       "1      1         0\n",
       "2      2         0\n",
       "3      3         0\n",
       "4      4         0\n",
       "..   ...       ...\n",
       "553  553         0\n",
       "554  554         0\n",
       "555  555         1\n",
       "556  556         0\n",
       "557  557         0\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_result = pd.DataFrame(columns=['Id','Predicted'], index=range(len(yhat)))\n",
    "for i in range(len(yhat)):\n",
    "    df_result['Id'][i] = i\n",
    "    if yhat[i][0] > yhat[i][1]:\n",
    "        df_result['Predicted'][i] = 0\n",
    "    else:\n",
    "        df_result['Predicted'][i] = 1\n",
    "\n",
    "\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7015b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('result03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25756213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
