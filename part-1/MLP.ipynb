{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english')) # note: stopwords are all in lowercase\n",
    "\n",
    "def tokenizing_english_xstopwords(tw_text):\n",
    "    \n",
    "#     text = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"URL\", text)  # Replace urls with special token\n",
    "#     text = text.replace(\"\\'s\", \"\")\n",
    "#     text = text.replace(\"\\'\", \"\")\n",
    "#     text = text.replace(\"n\\'t\", \" n\\'t\")\n",
    "#     text = text.replace(\"@\", \"\")\n",
    "#     text = text.replace(\"#\", \"\")\n",
    "#     text = text.replace(\"_\", \" \")\n",
    "#     text = text.replace(\"-\", \" \")\n",
    "#     text = text.replace(\"&amp;\", \"\")\n",
    "#     text = text.replace(\"&gt;\", \"\")\n",
    "#     text = text.replace(\"\\\"\", \"\")\n",
    "#     text = text.replace(\".\", \"\")\n",
    "#     text = text.replace(\",\", \"\")\n",
    "#     text = text.replace(\"(\", \"\")\n",
    "#     text = text.replace(\")\", \"\")\n",
    "#     text = ' '.join(text.split())\n",
    "    \n",
    "    \n",
    "    tw_token = tt.tokenize(tw_text)\n",
    "    tw_token_lower = [w.lower() for w in tw_token]\n",
    "    tw_token_lower_english = [w for w in tw_token_lower if w.isalpha()]\n",
    "    tw_token_lower_english_xstopword = [w for w in tw_token_lower_english if not w in stopwords]\n",
    "    return tw_token_lower_english_xstopword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52d9637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regularly rinsing nose saline help prevent inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>french police chief killed attack devastating ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus disease covid advice public wear m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ottawa police confirm multiple suspects shooti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>primary focus government alleviate suffering d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>desperate ted cruz claims planned parenthood s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>thoughts prayers enough pres obama speaks mass...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>police surrounded building suspected attackers...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>joseph smith translated gift power god come fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>help socialism need bad slacklining excellent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1895 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tw_text_re label0 label1\n",
       "0     regularly rinsing nose saline help prevent inf...      1      0\n",
       "1     french police chief killed attack devastating ...      0      1\n",
       "2     coronavirus disease covid advice public wear m...      1      0\n",
       "3     ottawa police confirm multiple suspects shooti...      1      0\n",
       "4     primary focus government alleviate suffering d...      1      0\n",
       "...                                                 ...    ...    ...\n",
       "1890  desperate ted cruz claims planned parenthood s...      0      1\n",
       "1891  thoughts prayers enough pres obama speaks mass...      0      1\n",
       "1892  police surrounded building suspected attackers...      1      0\n",
       "1893  joseph smith translated gift power god come fo...      1      0\n",
       "1894  help socialism need bad slacklining excellent ...      1      0\n",
       "\n",
       "[1895 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('train.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "labels = []\n",
    "with open('train.label.txt') as f:\n",
    "    labels = f.readlines()\n",
    "data_label = [lb.splitlines()[0] for lb in labels]\n",
    "data_label_01 = []\n",
    "for lb in data_label:\n",
    "    if lb == 'rumour':\n",
    "        data_label_01.append((0, 1))\n",
    "    else:\n",
    "        data_label_01.append((1, 0))\n",
    "\n",
    "\n",
    "tw_path = 'data/train-data/'\n",
    "col = ['tw_text_re', 'label0', 'label1']\n",
    "inx = range(len(data_label))\n",
    "data_train = pd.DataFrame(columns=col, index=inx)\n",
    "# data_train = pd.DataFrame(columns=col)\n",
    "# data_train['label'] = data_label\n",
    "# display(data_train)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "    \n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path+twid+'.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "    \n",
    "    # data_train['tw_text_re'][i] = tw_text_re\n",
    "    data_train['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "    data_train['label0'][i] = data_label_01[i][0]\n",
    "    data_train['label1'][i] = data_label_01[i][1]\n",
    "    \n",
    "\n",
    "data_train_drop = data_train.dropna().reset_index(drop=True)\n",
    "display(data_train_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "57dbd05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new low obama spent money close natl parks shu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news shots fired parliament hill follow develo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worry ppl threat homeland man wearing body arm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wash fruit vegetables time handling wash hands...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lit like rainbow awesome getting better light ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>obama pattern mass shootings country parallel ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>photo white house lit rainbow colors high gay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>covid virus transmitted areas hot humid climat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>number ppl killed mass shootings obama tenure ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>long incubation period covid incubation period...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tw_text_re label0 label1\n",
       "0     new low obama spent money close natl parks shu...      0      1\n",
       "1     news shots fired parliament hill follow develo...      1      0\n",
       "2     worry ppl threat homeland man wearing body arm...      0      1\n",
       "3     wash fruit vegetables time handling wash hands...      1      0\n",
       "4     lit like rainbow awesome getting better light ...      1      0\n",
       "...                                                 ...    ...    ...\n",
       "2945  obama pattern mass shootings country parallel ...      0      1\n",
       "2946  photo white house lit rainbow colors high gay ...      1      0\n",
       "2947  covid virus transmitted areas hot humid climat...      1      0\n",
       "2948  number ppl killed mass shootings obama tenure ...      0      1\n",
       "2949  long incubation period covid incubation period...      1      0\n",
       "\n",
       "[2950 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "label_arr = data_train_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "d = label_count_0 - label_count_1\n",
    "\n",
    "data_train_drop_1 = data_train_drop[data_train_drop['label1'] == 1]\n",
    "data_sample = data_train_drop_1.sample(n=d, replace=True, random_state=90042)\n",
    "data_train_drop = pd.concat([data_train_drop, data_sample], ignore_index = True).reset_index()\n",
    "\n",
    "data_train_drop = data_train_drop.drop(['index'], axis=1)\n",
    "data_train_drop = data_train_drop.to_numpy()\n",
    "np.random.shuffle(data_train_drop)\n",
    "data_train_drop = pd.DataFrame(data_train_drop, columns=['tw_text_re', 'label0', 'label1'])\n",
    "data_train_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0a5184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475\n",
      "1475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_arr = data_train_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "print(label_count_1)\n",
    "print(label_count_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d601598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid fact hand dryers effective killing new c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expect result pending antibody test please may...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid spread people catch covid others virus d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>every news outlet using headlines like antibio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>researcher encounter goliath birdeater largest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>cure covid however several ongoing clinical tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>speculation arrested banksy debuts new mural b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>questions answered reply number get correct an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>operation ku klux klan never stopped watching ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>exposing sun temperatures higher degrees preve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>632 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re label0 label1\n",
       "0    covid fact hand dryers effective killing new c...      1      0\n",
       "1    expect result pending antibody test please may...      1      0\n",
       "2    covid spread people catch covid others virus d...      1      0\n",
       "3    every news outlet using headlines like antibio...      1      0\n",
       "4    researcher encounter goliath birdeater largest...      1      0\n",
       "..                                                 ...    ...    ...\n",
       "627  cure covid however several ongoing clinical tr...      1      0\n",
       "628  speculation arrested banksy debuts new mural b...      0      1\n",
       "629  questions answered reply number get correct an...      1      0\n",
       "630  operation ku klux klan never stopped watching ...      0      1\n",
       "631  exposing sun temperatures higher degrees preve...      1      0\n",
       "\n",
       "[632 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# lines = []\n",
    "with open('dev.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "# labels = []\n",
    "with open('dev.label.txt') as f:\n",
    "    labels = f.readlines()\n",
    "data_label = [lb.splitlines()[0] for lb in labels]\n",
    "data_label_01 = []\n",
    "for lb in data_label:\n",
    "    if lb == 'rumour':\n",
    "        data_label_01.append((0, 1))\n",
    "    else:\n",
    "        data_label_01.append((1, 0))\n",
    "\n",
    "tw_path = 'data/dev-data/'\n",
    "col = ['tw_text_re', 'label0', 'label1']\n",
    "inx = range(len(data_label))\n",
    "data_dev = pd.DataFrame(columns=col, index=inx)\n",
    "# data_dev = pd.DataFrame(columns=col)\n",
    "# data_dev['label'] = data_label\n",
    "# display(data_dev)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "\n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path + twid + '.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "\n",
    "    # data_dev['tw_text_re'][i] = tw_text_re\n",
    "    data_dev['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "    data_dev['label0'][i] = data_label_01[i][0]\n",
    "    data_dev['label1'][i] = data_label_01[i][1]\n",
    "\n",
    "data_dev_drop = data_dev.dropna().reset_index(drop=True)\n",
    "display(data_dev_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4923b86b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live citizens assembly talk citizens assembly ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world health organization insists new coronavi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poll lead shrinks edge gop vanishes believe po...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptoms covid covid airborne answers biggest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>covid virus transmitted areas hot humid climat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>flu much bigger threat coronavirus written th ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>macklemore announced today joined isis lol mac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>exquisite good chop translucent butterfly beau...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>texas health officials say person test positiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re label0 label1\n",
       "0    live citizens assembly talk citizens assembly ...      1      0\n",
       "1    world health organization insists new coronavi...      1      0\n",
       "2    poll lead shrinks edge gop vanishes believe po...      0      1\n",
       "3    symptoms covid covid airborne answers biggest ...      1      0\n",
       "4                                                           1      0\n",
       "..                                                 ...    ...    ...\n",
       "981  covid virus transmitted areas hot humid climat...      1      0\n",
       "982  flu much bigger threat coronavirus written th ...      0      1\n",
       "983  macklemore announced today joined isis lol mac...      0      1\n",
       "984  exquisite good chop translucent butterfly beau...      0      1\n",
       "985  texas health officials say person test positiv...      1      0\n",
       "\n",
       "[986 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "label_arr = data_dev_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "d = label_count_0 - label_count_1\n",
    "\n",
    "data_dev_drop_1 = data_dev_drop[data_dev_drop['label1'] == 1]\n",
    "data_sample = data_dev_drop_1.sample(n=d, replace=True, random_state=90042)\n",
    "data_dev_drop = pd.concat([data_dev_drop, data_sample], ignore_index = True).reset_index()\n",
    "\n",
    "data_dev_drop = data_dev_drop.drop(['index'], axis=1)\n",
    "data_dev_drop = data_dev_drop.to_numpy()\n",
    "np.random.shuffle(data_dev_drop)\n",
    "data_dev_drop = pd.DataFrame(data_dev_drop, columns=['tw_text_re', 'label0', 'label1'])\n",
    "data_dev_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c02d19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_arr = data_dev_drop['label1'].to_numpy()\n",
    "label_count_1 = np.count_nonzero(label_arr == 1)\n",
    "label_count_0 = np.count_nonzero(label_arr == 0)\n",
    "print(label_count_1)\n",
    "print(label_count_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_text_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid spread thanks wcco station trust media p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate keep saying capitalism implode without vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q covid influenza viruses different q covid in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una de les q coronaviruses de la pàgina web de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely blame politicians whoever else invo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>man dies disease situação meio que irônica man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>holy shit doritos flavored mountain dew lost a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>banksy account joins cartoonists support je su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>q members international heal q members adviser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>covid caught person symptoms main way disease ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tw_text_re\n",
       "0    covid spread thanks wcco station trust media p...\n",
       "1    hate keep saying capitalism implode without vi...\n",
       "2    q covid influenza viruses different q covid in...\n",
       "3    una de les q coronaviruses de la pàgina web de...\n",
       "4    absolutely blame politicians whoever else invo...\n",
       "..                                                 ...\n",
       "553  man dies disease situação meio que irônica man...\n",
       "554  holy shit doritos flavored mountain dew lost a...\n",
       "555  banksy account joins cartoonists support je su...\n",
       "556  q members international heal q members adviser...\n",
       "557  covid caught person symptoms main way disease ...\n",
       "\n",
       "[558 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# lines = []\n",
    "with open('test.data.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "\n",
    "tw_path = 'data/tweet-objects/'\n",
    "col = ['tw_text_re']\n",
    "inx = range(len(data_label))\n",
    "data_test = pd.DataFrame(columns=col, index=inx)\n",
    "# display(data_test)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    twtw = line.splitlines()[0]\n",
    "    tw_list = str(twtw).split(',')\n",
    "\n",
    "    tw_text_re = []\n",
    "    for twid in tw_list:\n",
    "        try:\n",
    "            with open(tw_path + twid + '.json') as f:\n",
    "                tw_object = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        text = tw_object['text']\n",
    "        tw_tokenized = tokenizing_english_xstopwords(text)\n",
    "        tw_text_re += tw_tokenized\n",
    "\n",
    "    # data_test['tw_text_re'][i] = tw_text_re\n",
    "    data_test['tw_text_re'][i] = ' '.join(map(str, tw_text_re))\n",
    "\n",
    "data_test_drop = data_test.dropna().reset_index(drop=True)\n",
    "display(data_test_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b63374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train, y_train = data_train_drop.loc[:, 'tw_text_re'], data_train_drop.loc[:, 'label0':'label1']\n",
    "x_dev, y_dev = data_dev_drop.loc[:, 'tw_text_re'], data_dev_drop.loc[:, 'label0':'label1']\n",
    "x_test = data_test_drop.loc[:, 'tw_text_re']\n",
    "\n",
    "x_train = np.array(x_train)#.astype(np.float32)\n",
    "x_dev = np.array(x_dev)#.astype(np.float32)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "y_dev = np.array(y_dev).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d9aa6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01e11040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d21db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f042099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f1b0b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 17221\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode=\"count\") #BOW representation\n",
    "x_dev = tokenizer.texts_to_matrix(x_dev, mode=\"count\") #BOW representation\n",
    "x_test = tokenizer.texts_to_matrix(x_test, mode=\"count\") #BOW representation\n",
    "\n",
    "vocab_size = x_train.shape[1]\n",
    "print(\"Vocab size =\", vocab_size)\n",
    "# print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38026e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feedforward-bow-input\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 1000)              17222000  \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 18,225,002\n",
      "Trainable params: 18,225,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 13s 134ms/step - loss: 0.4598 - accuracy: 0.8213 - val_loss: 0.5466 - val_accuracy: 0.8073\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 11s 118ms/step - loss: 0.0414 - accuracy: 0.9843 - val_loss: 0.4518 - val_accuracy: 0.8641\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 12s 132ms/step - loss: 0.0329 - accuracy: 0.9845 - val_loss: 0.5236 - val_accuracy: 0.8671\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 13s 138ms/step - loss: 0.0307 - accuracy: 0.9839 - val_loss: 0.6385 - val_accuracy: 0.8387\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 45s 489ms/step - loss: 0.0329 - accuracy: 0.9835 - val_loss: 0.6651 - val_accuracy: 0.8367\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 15s 163ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.6111 - val_accuracy: 0.8479\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 15s 163ms/step - loss: 0.0307 - accuracy: 0.9835 - val_loss: 0.7407 - val_accuracy: 0.8316\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 13s 137ms/step - loss: 0.0283 - accuracy: 0.9858 - val_loss: 0.7353 - val_accuracy: 0.8367\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 11s 116ms/step - loss: 0.0281 - accuracy: 0.9861 - val_loss: 0.7645 - val_accuracy: 0.8347\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 10s 107ms/step - loss: 0.0286 - accuracy: 0.9873 - val_loss: 0.6261 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 11s 120ms/step - loss: 0.0268 - accuracy: 0.9859 - val_loss: 0.7045 - val_accuracy: 0.8377\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 10s 109ms/step - loss: 0.0291 - accuracy: 0.9856 - val_loss: 0.6482 - val_accuracy: 0.8489\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 10s 108ms/step - loss: 0.0293 - accuracy: 0.9828 - val_loss: 0.7265 - val_accuracy: 0.8367\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 11s 119ms/step - loss: 0.0285 - accuracy: 0.9868 - val_loss: 0.7205 - val_accuracy: 0.8458\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 11s 115ms/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 0.7490 - val_accuracy: 0.8408\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 14s 147ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 0.6786 - val_accuracy: 0.8479\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 18s 192ms/step - loss: 0.0272 - accuracy: 0.9864 - val_loss: 0.7804 - val_accuracy: 0.8367\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 19s 205ms/step - loss: 0.0285 - accuracy: 0.9867 - val_loss: 0.7264 - val_accuracy: 0.8489\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.0293 - accuracy: 0.9842 - val_loss: 0.8464 - val_accuracy: 0.8245\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.0256 - accuracy: 0.9886 - val_loss: 0.7234 - val_accuracy: 0.8428\n",
      "\n",
      "Testing Accuracy:  0.8428\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "#model definition\n",
    "model = Sequential(name=\"feedforward-bow-input\")\n",
    "# model.add(layers.Dense(10, input_dim=vocab_size, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.add(layers.Dense(1000, input_dim=vocab_size, activation='elu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1000, activation='elu'))\n",
    "# model.add(layers.Dense(10, activation='elu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "#since it's a binary classification problem, we use a binary cross entropy loss here binary_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#training\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, verbose=True, validation_data=(x_dev, y_dev), batch_size=32)\n",
    "# model.fit(x_train, y_train, epochs=20, verbose=True, batch_size=16)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_dev, y_dev, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6273c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b1836154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9717879e-01, 2.8211770e-03],\n",
       "       [1.0000000e+00, 2.9298658e-08],\n",
       "       [9.9981779e-01, 1.8219123e-04],\n",
       "       ...,\n",
       "       [5.3621910e-04, 9.9946374e-01],\n",
       "       [9.9999666e-01, 3.3396727e-06],\n",
       "       [9.9999988e-01, 1.1146662e-07]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "yhat = model.predict(x_test)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e206c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "797e9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = yhat.copy()\n",
    "# result[result>=0.5] = 1\n",
    "# result[result<0.5] = 0\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d7d2865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Predicted\n",
       "0      0         0\n",
       "1      1         0\n",
       "2      2         0\n",
       "3      3         0\n",
       "4      4         0\n",
       "..   ...       ...\n",
       "553  553         0\n",
       "554  554         0\n",
       "555  555         1\n",
       "556  556         0\n",
       "557  557         0\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_result = pd.DataFrame(columns=['Id','Predicted'], index=range(len(yhat)))\n",
    "for i in range(len(yhat)):\n",
    "    df_result['Id'][i] = i\n",
    "    if yhat[i][0] > yhat[i][1]:\n",
    "        df_result['Predicted'][i] = 0\n",
    "    else:\n",
    "        df_result['Predicted'][i] = 1\n",
    "\n",
    "\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7015b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('result03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25756213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
