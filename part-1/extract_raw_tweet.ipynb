{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import re\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Data(data_file, data_json, label_file):\n",
    "    # open train.txt\n",
    "    with open(data_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    jsonFiles = glob(data_json + '/*.json')\n",
    "    \n",
    "    # extract tweet ids from train_data.json names\n",
    "    regex = re.compile('[0-9]{12,22}')\n",
    "    json_lst = []\n",
    "    for j in jsonFiles:   \n",
    "        b=regex.findall(j)\n",
    "        json_lst.append(b)\n",
    "    \n",
    "    data_list = {}\n",
    "    num = 0\n",
    "    \n",
    "    # extract labels\n",
    "    labels = []\n",
    "    if label_file:\n",
    "        with open(label_file) as f:\n",
    "            label_lines = f.readlines()\n",
    "        for label in label_lines:\n",
    "            if label.strip('\\n') == 'rumour':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        tweets = lines[i].strip('\\n').split(',')\n",
    "        target_tweet = {}\n",
    "        retweets = []\n",
    "\n",
    "        if [tweets[0]] in json_lst:\n",
    "    \n",
    "            for j in range(len(tweets)):\n",
    "                filePath = data_json+tweets[j]+'.json'\n",
    "                if j == 0 :\n",
    "                    json_data_file = open(filePath,'r').read()\n",
    "                    json_data = json.loads(json_data_file)\n",
    "                    \n",
    "                    target_tweet['source tweet id']=json_data['id_str']\n",
    "                    target_tweet['source tweet text']=json_data['text']\n",
    "       \n",
    "                if j!=0 and [tweets[j]] in json_lst:\n",
    "                    json_data_file = open(filePath,'r').read()\n",
    "                    json_data = json.loads(json_data_file)\n",
    "\n",
    "                    # list the retweets in a chronongical order\n",
    "                    retweets.append((time.strptime(json_data['created_at'],'%a %b %d %H:%M:%S %z %Y'), json_data['text']))\n",
    "                    sort_time_retweets = sorted(retweets, key=lambda x: x[0])\n",
    "                    sort_retweets = [t[1] for t in sort_time_retweets]\n",
    "                    target_tweet['retweets']=sort_retweets\n",
    "\n",
    "            data_list[num] = target_tweet\n",
    "            num += 1\n",
    "        elif label_file:\n",
    "            labels[i] = 2\n",
    "            \n",
    "    labels = list(filter((2).__ne__, labels))\n",
    "        \n",
    "    return data_list, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = 'train.data.txt'\n",
    "train_data_json = 'train-data/'\n",
    "train_label_file = 'train.label.txt'\n",
    "\n",
    "train_data_d, train_labels=read_Data(train_data_file,train_data_json,train_label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_labels))\n",
    "print(len(train_data_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(train_data_d).T\n",
    "# data.to_json(r'total_train_data.json')\n",
    "# data_label = pd.DataFrame(train_labels).T\n",
    "# data_label.to_json(r'total_train_data_labels.json')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('total_train_data.json', 'w') as f:\n",
    "    json.dump(train_data_d, f)\n",
    "with open('total_train_data_labels.json', 'w') as f:\n",
    "    json.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_file = 'dev.data.txt'\n",
    "dev_data_json = 'dev-data/'\n",
    "dev_label_file = 'dev.label.txt'\n",
    "\n",
    "dev_data_d, dev_labels=read_Data(dev_data_file,dev_data_json,dev_label_file)\n",
    "print(len(dev_labels))\n",
    "print(len(dev_data_d))\n",
    "\n",
    "# dev_data = pd.DataFrame(dev_data_d).T\n",
    "# dev_data.to_json(r'total_dev_data.json')\n",
    "# dev_data_label = pd.DataFrame(dev_labels).T\n",
    "# dev_data_label.to_json(r'total_dev_data_labels.json')\n",
    "# dev_data_label\n",
    "# dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('total_dev_data.json', 'w') as f:\n",
    "    json.dump(dev_data_d, f)\n",
    "with open('total_dev_data_labels.json', 'w') as f:\n",
    "    json.dump(dev_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = 'test.data.txt'\n",
    "test_data_json = 'test-data/'\n",
    "\n",
    "test_data_d, test_labels=read_Data(test_data_file,test_data_json,\"\")\n",
    "print(len(test_data_d))\n",
    "\n",
    "with open('total_test_data.json', 'w') as f:\n",
    "    json.dump(test_data_d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine source tweet and retweet together \n",
    "\n",
    "train_lst = []\n",
    "for i in range(len(train_data_d)):\n",
    "    tweets = train_data_d[i].get('source tweet text','')\n",
    "    \n",
    "    for tweet in train_data_d[i].get('retweets',''):\n",
    "        tweets+=tweet\n",
    "    train_lst.append(tweets)\n",
    "\n",
    "print(len(train_lst))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_lst = []\n",
    "for i in range(len(dev_data_d)):\n",
    "    tweets = dev_data_d[i].get('source tweet text','')\n",
    "    \n",
    "    for tweet in dev_data_d[i].get('retweets',''):\n",
    "        tweets+=tweet\n",
    "    dev_lst.append(tweets)\n",
    "\n",
    "print(len(dev_lst))\n",
    "print(len(dev_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
